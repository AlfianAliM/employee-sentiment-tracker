{"cells":[{"cell_type":"markdown","metadata":{"id":"KH2r0S8HlB9t"},"source":["# Import Library"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":25910,"status":"ok","timestamp":1717902981377,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"rTGwFRBTg1Gy"},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Project\\Final Project Indonesia AI\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import pandas as pd\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":94141,"status":"ok","timestamp":1717888889285,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"SCbo2Tfr606I","outputId":"82a89c96-4b2b-4622-cdc6-25f4f0efe3da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n","Collecting accelerate>=0.21.0 (from transformers[torch])\n","  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n","Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}],"source":["# !pip install transformers[torch]"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107366,"status":"ok","timestamp":1717889950536,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"zkaeZUNcLj9Y","outputId":"f5e362d2-b746-4c4a-bcbf-8e0476601eb5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting accelerate[torch]\n","  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/309.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/309.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: accelerate 0.31.0 does not provide the extra 'torch'\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate[torch]) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate[torch]) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate[torch]) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate[torch]) (2.3.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate[torch]) (0.23.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate[torch]) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate[torch]) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate[torch]) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate[torch]) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate[torch]) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate[torch]) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate[torch])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate[torch])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate[torch])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate[torch])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate[torch])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate[torch])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate[torch])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate[torch])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate[torch])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate[torch])\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate[torch])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate[torch]) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate[torch])\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate[torch]) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate[torch]) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate[torch]) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate[torch]) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate[torch]) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n","Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}],"source":["# !pip install accelerate[torch]"]},{"cell_type":"markdown","metadata":{"id":"_JoQEpLcu7mp"},"source":["# Sentiment Analysist Use Pretrained Model BERT Uncased + Fine tuned using row dataset\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7985,"status":"ok","timestamp":1717890029576,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"g_z8giPdu6Wc"},"outputs":[],"source":["df = pd.read_excel('lowercase_labels_datasets.xlsx')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['text', 'sentiment'], dtype='object')\n"]}],"source":["df\n","print(df.columns)"]},{"cell_type":"markdown","metadata":{"id":"mlU2osXfh5XC"},"source":["## pre processing:\n","- drop N/A"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1717890029577,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"Vw_c-_B6-fkh","outputId":"d07ffd5c-a807-4ac6-9943-f3f4d61a60b9"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>deserved candidate promoted promptly unbiased ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>got lot learning platform monthly learning pla...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>based business unit get experience company pol...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>client project good use latest tech work</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>worked ibm year tc year rd company year comple...</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  sentiment\n","0  deserved candidate promoted promptly unbiased ...        1.0\n","1  got lot learning platform monthly learning pla...        1.0\n","2  based business unit get experience company pol...        1.0\n","3           client project good use latest tech work        1.0\n","4  worked ibm year tc year rd company year comple...        1.0"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1717890029578,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"1J5iY2Y2I_py"},"outputs":[],"source":["# Remove rows with missing or invalid text data\n","df.dropna(subset=['text', 'sentiment'], inplace=True)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["46416"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["len(df)"]},{"cell_type":"markdown","metadata":{"id":"FhR_6TUgiyxX"},"source":["## preparation for sentiment analysis, consists:\n","- encode labels\n","- split data\n","- tokenize the text column on train and val"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1717890030147,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"F0mg-Szb57FH"},"outputs":[],"source":["# Encode sentiment labels\n","label_encoder = LabelEncoder()\n","df['sentiment'] = label_encoder.fit_transform(df['sentiment'])"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1717890030148,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"Ul4As54KhKDs"},"outputs":[],"source":["# Split data into train and test sets\n","train_texts, val_texts, train_labels, val_labels = train_test_split(df['text'].tolist(), df['sentiment'].tolist(), test_size=0.2)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1717890030148,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"EnMdPYbuHW0T","outputId":"b1c168ad-6151-4589-a832-62c74547cb85"},"outputs":[{"name":"stdout","output_type":"stream","text":["First 5 train texts: ['as of now nothing from my end because everything going smooth for me.', 'nothing to like here', 'connect with other team to due team work', 'everything', 'just the compensation part']\n","First 5 train labels: [0, 1, 1, 1, 0]\n","First 5 val texts: ['bad behavior in bench time, work life balance is total on client wish for good or bad environment, appraisal is poor and in some project senior are doing micro management.', 'work atmosphere', 'now a days the way of handling projects become too difficult.', 'the best environment to work and very understanding manager . work flexibility is there and many more.', 'best work culture']\n","First 5 val labels: [0, 1, 0, 1, 1]\n"]}],"source":["# Debugging: Print first few entries\n","print(\"First 5 train texts:\", train_texts[:5])\n","print(\"First 5 train labels:\", train_labels[:5])\n","print(\"First 5 val texts:\", val_texts[:5])\n","print(\"First 5 val labels:\", val_labels[:5])"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4971,"status":"ok","timestamp":1717890035112,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"hCP1rXnDfk22","outputId":"f8b0095c-34e9-414a-a4f9-08d0be4baac7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)  # 2 classes: negative and positive\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":22802,"status":"ok","timestamp":1717890057909,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"ZgFYg6RNBRtg"},"outputs":[],"source":["# Tokenize data\n","train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=128)\n","val_encodings = tokenizer(val_texts, padding=True, truncation=True, max_length=128)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1717890057909,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"JekMgeJSJXek"},"outputs":[],"source":["# Create torch dataset\n","class SentimentDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = SentimentDataset(train_encodings, train_labels)\n","val_dataset = SentimentDataset(val_encodings, val_labels)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11778,"status":"ok","timestamp":1717890069668,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"6JfTkYw4Nn5f","outputId":"9424d626-2b17-4caf-cac4-f6fb032cd17f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Name: accelerate\n","Version: 0.31.0\n","Summary: Accelerate\n","Home-page: https://github.com/huggingface/accelerate\n","Author: The HuggingFace team\n","Author-email: zach.mueller@huggingface.co\n","License: Apache\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n","Required-by: \n"]}],"source":["!pip show accelerate"]},{"cell_type":"markdown","metadata":{"id":"NpRVpwgLjcP7"},"source":["## fine tuned, results, and save.\n","\n","The fine tuned consists:\n","- epoch: 3\n","-  bath size: 16"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1717890069669,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"qhfPWPAoJZwf"},"outputs":[],"source":["# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=10,\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1717890069669,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"JRHs9MhpJc1u"},"outputs":[],"source":["# Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n",")\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2593456,"status":"ok","timestamp":1717892663117,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"6DczkPQVNJX_","outputId":"4b8ced52-2647-44be-dfa8-71d9452768ab"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='7032' max='7032' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7032/7032 43:10, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.722500</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.736300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.718100</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.703800</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.714700</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.689500</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.687900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.666800</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.668100</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.651800</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.649600</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.641200</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.637600</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.605500</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.619500</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.630600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.621200</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.652100</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.591400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.574800</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.615200</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.686700</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.589800</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.668400</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.600600</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.535100</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.662700</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.597900</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.597400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.626800</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.663300</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.617100</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.610800</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.648700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.635900</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.636900</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.629900</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.596400</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.574200</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.617300</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.647900</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.619800</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.604900</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.654400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.571800</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.634600</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.620900</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.522600</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.527000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.655400</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.579400</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.588400</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.669900</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.587000</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.531000</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.679100</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.565300</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.645600</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.625500</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.619000</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.657000</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.645100</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.659500</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.696800</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.617600</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.593700</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.640200</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>0.597600</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>0.596000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.572700</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>0.457200</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>0.557300</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>0.643300</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>0.567500</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.616700</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>0.588700</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>0.626600</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>0.626200</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>0.564100</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.614300</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>0.619400</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>0.546900</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>0.644500</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>0.615500</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.619000</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>0.568100</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>0.515300</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>0.605000</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>0.568800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.610000</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>0.640100</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>0.556400</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>0.573600</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>0.610200</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.636100</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>0.680600</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>0.591500</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>0.655000</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>0.656200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.634000</td>\n","    </tr>\n","    <tr>\n","      <td>1010</td>\n","      <td>0.670400</td>\n","    </tr>\n","    <tr>\n","      <td>1020</td>\n","      <td>0.613900</td>\n","    </tr>\n","    <tr>\n","      <td>1030</td>\n","      <td>0.606700</td>\n","    </tr>\n","    <tr>\n","      <td>1040</td>\n","      <td>0.660700</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.619600</td>\n","    </tr>\n","    <tr>\n","      <td>1060</td>\n","      <td>0.586900</td>\n","    </tr>\n","    <tr>\n","      <td>1070</td>\n","      <td>0.565000</td>\n","    </tr>\n","    <tr>\n","      <td>1080</td>\n","      <td>0.634900</td>\n","    </tr>\n","    <tr>\n","      <td>1090</td>\n","      <td>0.613000</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.597800</td>\n","    </tr>\n","    <tr>\n","      <td>1110</td>\n","      <td>0.599500</td>\n","    </tr>\n","    <tr>\n","      <td>1120</td>\n","      <td>0.604300</td>\n","    </tr>\n","    <tr>\n","      <td>1130</td>\n","      <td>0.612100</td>\n","    </tr>\n","    <tr>\n","      <td>1140</td>\n","      <td>0.607200</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.614000</td>\n","    </tr>\n","    <tr>\n","      <td>1160</td>\n","      <td>0.594600</td>\n","    </tr>\n","    <tr>\n","      <td>1170</td>\n","      <td>0.671000</td>\n","    </tr>\n","    <tr>\n","      <td>1180</td>\n","      <td>0.627500</td>\n","    </tr>\n","    <tr>\n","      <td>1190</td>\n","      <td>0.589700</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.564800</td>\n","    </tr>\n","    <tr>\n","      <td>1210</td>\n","      <td>0.607200</td>\n","    </tr>\n","    <tr>\n","      <td>1220</td>\n","      <td>0.594800</td>\n","    </tr>\n","    <tr>\n","      <td>1230</td>\n","      <td>0.606400</td>\n","    </tr>\n","    <tr>\n","      <td>1240</td>\n","      <td>0.608700</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.577000</td>\n","    </tr>\n","    <tr>\n","      <td>1260</td>\n","      <td>0.599200</td>\n","    </tr>\n","    <tr>\n","      <td>1270</td>\n","      <td>0.617500</td>\n","    </tr>\n","    <tr>\n","      <td>1280</td>\n","      <td>0.582900</td>\n","    </tr>\n","    <tr>\n","      <td>1290</td>\n","      <td>0.607500</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.617400</td>\n","    </tr>\n","    <tr>\n","      <td>1310</td>\n","      <td>0.658400</td>\n","    </tr>\n","    <tr>\n","      <td>1320</td>\n","      <td>0.600600</td>\n","    </tr>\n","    <tr>\n","      <td>1330</td>\n","      <td>0.596100</td>\n","    </tr>\n","    <tr>\n","      <td>1340</td>\n","      <td>0.620300</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.618500</td>\n","    </tr>\n","    <tr>\n","      <td>1360</td>\n","      <td>0.582400</td>\n","    </tr>\n","    <tr>\n","      <td>1370</td>\n","      <td>0.642900</td>\n","    </tr>\n","    <tr>\n","      <td>1380</td>\n","      <td>0.622300</td>\n","    </tr>\n","    <tr>\n","      <td>1390</td>\n","      <td>0.553800</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.560800</td>\n","    </tr>\n","    <tr>\n","      <td>1410</td>\n","      <td>0.632200</td>\n","    </tr>\n","    <tr>\n","      <td>1420</td>\n","      <td>0.534900</td>\n","    </tr>\n","    <tr>\n","      <td>1430</td>\n","      <td>0.622100</td>\n","    </tr>\n","    <tr>\n","      <td>1440</td>\n","      <td>0.661800</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.620200</td>\n","    </tr>\n","    <tr>\n","      <td>1460</td>\n","      <td>0.592300</td>\n","    </tr>\n","    <tr>\n","      <td>1470</td>\n","      <td>0.565900</td>\n","    </tr>\n","    <tr>\n","      <td>1480</td>\n","      <td>0.598200</td>\n","    </tr>\n","    <tr>\n","      <td>1490</td>\n","      <td>0.544200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.596800</td>\n","    </tr>\n","    <tr>\n","      <td>1510</td>\n","      <td>0.527000</td>\n","    </tr>\n","    <tr>\n","      <td>1520</td>\n","      <td>0.557200</td>\n","    </tr>\n","    <tr>\n","      <td>1530</td>\n","      <td>0.683600</td>\n","    </tr>\n","    <tr>\n","      <td>1540</td>\n","      <td>0.663100</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.656900</td>\n","    </tr>\n","    <tr>\n","      <td>1560</td>\n","      <td>0.635300</td>\n","    </tr>\n","    <tr>\n","      <td>1570</td>\n","      <td>0.580600</td>\n","    </tr>\n","    <tr>\n","      <td>1580</td>\n","      <td>0.606500</td>\n","    </tr>\n","    <tr>\n","      <td>1590</td>\n","      <td>0.579300</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.588600</td>\n","    </tr>\n","    <tr>\n","      <td>1610</td>\n","      <td>0.629500</td>\n","    </tr>\n","    <tr>\n","      <td>1620</td>\n","      <td>0.611700</td>\n","    </tr>\n","    <tr>\n","      <td>1630</td>\n","      <td>0.694600</td>\n","    </tr>\n","    <tr>\n","      <td>1640</td>\n","      <td>0.653900</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.623900</td>\n","    </tr>\n","    <tr>\n","      <td>1660</td>\n","      <td>0.615500</td>\n","    </tr>\n","    <tr>\n","      <td>1670</td>\n","      <td>0.620100</td>\n","    </tr>\n","    <tr>\n","      <td>1680</td>\n","      <td>0.582700</td>\n","    </tr>\n","    <tr>\n","      <td>1690</td>\n","      <td>0.590200</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.556500</td>\n","    </tr>\n","    <tr>\n","      <td>1710</td>\n","      <td>0.573900</td>\n","    </tr>\n","    <tr>\n","      <td>1720</td>\n","      <td>0.556800</td>\n","    </tr>\n","    <tr>\n","      <td>1730</td>\n","      <td>0.580800</td>\n","    </tr>\n","    <tr>\n","      <td>1740</td>\n","      <td>0.577600</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.595000</td>\n","    </tr>\n","    <tr>\n","      <td>1760</td>\n","      <td>0.639400</td>\n","    </tr>\n","    <tr>\n","      <td>1770</td>\n","      <td>0.548900</td>\n","    </tr>\n","    <tr>\n","      <td>1780</td>\n","      <td>0.659000</td>\n","    </tr>\n","    <tr>\n","      <td>1790</td>\n","      <td>0.647200</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.600900</td>\n","    </tr>\n","    <tr>\n","      <td>1810</td>\n","      <td>0.622500</td>\n","    </tr>\n","    <tr>\n","      <td>1820</td>\n","      <td>0.545600</td>\n","    </tr>\n","    <tr>\n","      <td>1830</td>\n","      <td>0.594000</td>\n","    </tr>\n","    <tr>\n","      <td>1840</td>\n","      <td>0.565800</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.572300</td>\n","    </tr>\n","    <tr>\n","      <td>1860</td>\n","      <td>0.578900</td>\n","    </tr>\n","    <tr>\n","      <td>1870</td>\n","      <td>0.505800</td>\n","    </tr>\n","    <tr>\n","      <td>1880</td>\n","      <td>0.555700</td>\n","    </tr>\n","    <tr>\n","      <td>1890</td>\n","      <td>0.687700</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.582400</td>\n","    </tr>\n","    <tr>\n","      <td>1910</td>\n","      <td>0.633100</td>\n","    </tr>\n","    <tr>\n","      <td>1920</td>\n","      <td>0.599500</td>\n","    </tr>\n","    <tr>\n","      <td>1930</td>\n","      <td>0.521500</td>\n","    </tr>\n","    <tr>\n","      <td>1940</td>\n","      <td>0.540200</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.553500</td>\n","    </tr>\n","    <tr>\n","      <td>1960</td>\n","      <td>0.569900</td>\n","    </tr>\n","    <tr>\n","      <td>1970</td>\n","      <td>0.620200</td>\n","    </tr>\n","    <tr>\n","      <td>1980</td>\n","      <td>0.582800</td>\n","    </tr>\n","    <tr>\n","      <td>1990</td>\n","      <td>0.590100</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.653200</td>\n","    </tr>\n","    <tr>\n","      <td>2010</td>\n","      <td>0.651900</td>\n","    </tr>\n","    <tr>\n","      <td>2020</td>\n","      <td>0.569100</td>\n","    </tr>\n","    <tr>\n","      <td>2030</td>\n","      <td>0.581200</td>\n","    </tr>\n","    <tr>\n","      <td>2040</td>\n","      <td>0.596200</td>\n","    </tr>\n","    <tr>\n","      <td>2050</td>\n","      <td>0.610500</td>\n","    </tr>\n","    <tr>\n","      <td>2060</td>\n","      <td>0.606200</td>\n","    </tr>\n","    <tr>\n","      <td>2070</td>\n","      <td>0.556900</td>\n","    </tr>\n","    <tr>\n","      <td>2080</td>\n","      <td>0.573600</td>\n","    </tr>\n","    <tr>\n","      <td>2090</td>\n","      <td>0.582300</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.625100</td>\n","    </tr>\n","    <tr>\n","      <td>2110</td>\n","      <td>0.616800</td>\n","    </tr>\n","    <tr>\n","      <td>2120</td>\n","      <td>0.611200</td>\n","    </tr>\n","    <tr>\n","      <td>2130</td>\n","      <td>0.591000</td>\n","    </tr>\n","    <tr>\n","      <td>2140</td>\n","      <td>0.590900</td>\n","    </tr>\n","    <tr>\n","      <td>2150</td>\n","      <td>0.519800</td>\n","    </tr>\n","    <tr>\n","      <td>2160</td>\n","      <td>0.604000</td>\n","    </tr>\n","    <tr>\n","      <td>2170</td>\n","      <td>0.547800</td>\n","    </tr>\n","    <tr>\n","      <td>2180</td>\n","      <td>0.606800</td>\n","    </tr>\n","    <tr>\n","      <td>2190</td>\n","      <td>0.643700</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.567000</td>\n","    </tr>\n","    <tr>\n","      <td>2210</td>\n","      <td>0.552700</td>\n","    </tr>\n","    <tr>\n","      <td>2220</td>\n","      <td>0.601200</td>\n","    </tr>\n","    <tr>\n","      <td>2230</td>\n","      <td>0.525900</td>\n","    </tr>\n","    <tr>\n","      <td>2240</td>\n","      <td>0.630200</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.583500</td>\n","    </tr>\n","    <tr>\n","      <td>2260</td>\n","      <td>0.599500</td>\n","    </tr>\n","    <tr>\n","      <td>2270</td>\n","      <td>0.577100</td>\n","    </tr>\n","    <tr>\n","      <td>2280</td>\n","      <td>0.584500</td>\n","    </tr>\n","    <tr>\n","      <td>2290</td>\n","      <td>0.584500</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.599500</td>\n","    </tr>\n","    <tr>\n","      <td>2310</td>\n","      <td>0.591500</td>\n","    </tr>\n","    <tr>\n","      <td>2320</td>\n","      <td>0.585400</td>\n","    </tr>\n","    <tr>\n","      <td>2330</td>\n","      <td>0.606300</td>\n","    </tr>\n","    <tr>\n","      <td>2340</td>\n","      <td>0.632600</td>\n","    </tr>\n","    <tr>\n","      <td>2350</td>\n","      <td>0.596300</td>\n","    </tr>\n","    <tr>\n","      <td>2360</td>\n","      <td>0.609600</td>\n","    </tr>\n","    <tr>\n","      <td>2370</td>\n","      <td>0.524900</td>\n","    </tr>\n","    <tr>\n","      <td>2380</td>\n","      <td>0.536700</td>\n","    </tr>\n","    <tr>\n","      <td>2390</td>\n","      <td>0.623800</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.639700</td>\n","    </tr>\n","    <tr>\n","      <td>2410</td>\n","      <td>0.563800</td>\n","    </tr>\n","    <tr>\n","      <td>2420</td>\n","      <td>0.586700</td>\n","    </tr>\n","    <tr>\n","      <td>2430</td>\n","      <td>0.552000</td>\n","    </tr>\n","    <tr>\n","      <td>2440</td>\n","      <td>0.592900</td>\n","    </tr>\n","    <tr>\n","      <td>2450</td>\n","      <td>0.547300</td>\n","    </tr>\n","    <tr>\n","      <td>2460</td>\n","      <td>0.546800</td>\n","    </tr>\n","    <tr>\n","      <td>2470</td>\n","      <td>0.502300</td>\n","    </tr>\n","    <tr>\n","      <td>2480</td>\n","      <td>0.607200</td>\n","    </tr>\n","    <tr>\n","      <td>2490</td>\n","      <td>0.597400</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.566500</td>\n","    </tr>\n","    <tr>\n","      <td>2510</td>\n","      <td>0.500500</td>\n","    </tr>\n","    <tr>\n","      <td>2520</td>\n","      <td>0.519400</td>\n","    </tr>\n","    <tr>\n","      <td>2530</td>\n","      <td>0.550200</td>\n","    </tr>\n","    <tr>\n","      <td>2540</td>\n","      <td>0.530800</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>0.550900</td>\n","    </tr>\n","    <tr>\n","      <td>2560</td>\n","      <td>0.519100</td>\n","    </tr>\n","    <tr>\n","      <td>2570</td>\n","      <td>0.617100</td>\n","    </tr>\n","    <tr>\n","      <td>2580</td>\n","      <td>0.603600</td>\n","    </tr>\n","    <tr>\n","      <td>2590</td>\n","      <td>0.587400</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.574600</td>\n","    </tr>\n","    <tr>\n","      <td>2610</td>\n","      <td>0.572800</td>\n","    </tr>\n","    <tr>\n","      <td>2620</td>\n","      <td>0.558800</td>\n","    </tr>\n","    <tr>\n","      <td>2630</td>\n","      <td>0.603600</td>\n","    </tr>\n","    <tr>\n","      <td>2640</td>\n","      <td>0.506200</td>\n","    </tr>\n","    <tr>\n","      <td>2650</td>\n","      <td>0.632900</td>\n","    </tr>\n","    <tr>\n","      <td>2660</td>\n","      <td>0.571300</td>\n","    </tr>\n","    <tr>\n","      <td>2670</td>\n","      <td>0.605200</td>\n","    </tr>\n","    <tr>\n","      <td>2680</td>\n","      <td>0.564700</td>\n","    </tr>\n","    <tr>\n","      <td>2690</td>\n","      <td>0.520100</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.535800</td>\n","    </tr>\n","    <tr>\n","      <td>2710</td>\n","      <td>0.609300</td>\n","    </tr>\n","    <tr>\n","      <td>2720</td>\n","      <td>0.512200</td>\n","    </tr>\n","    <tr>\n","      <td>2730</td>\n","      <td>0.551800</td>\n","    </tr>\n","    <tr>\n","      <td>2740</td>\n","      <td>0.591800</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.494900</td>\n","    </tr>\n","    <tr>\n","      <td>2760</td>\n","      <td>0.629000</td>\n","    </tr>\n","    <tr>\n","      <td>2770</td>\n","      <td>0.612000</td>\n","    </tr>\n","    <tr>\n","      <td>2780</td>\n","      <td>0.625800</td>\n","    </tr>\n","    <tr>\n","      <td>2790</td>\n","      <td>0.606700</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.505100</td>\n","    </tr>\n","    <tr>\n","      <td>2810</td>\n","      <td>0.608700</td>\n","    </tr>\n","    <tr>\n","      <td>2820</td>\n","      <td>0.608300</td>\n","    </tr>\n","    <tr>\n","      <td>2830</td>\n","      <td>0.580300</td>\n","    </tr>\n","    <tr>\n","      <td>2840</td>\n","      <td>0.546200</td>\n","    </tr>\n","    <tr>\n","      <td>2850</td>\n","      <td>0.568600</td>\n","    </tr>\n","    <tr>\n","      <td>2860</td>\n","      <td>0.559000</td>\n","    </tr>\n","    <tr>\n","      <td>2870</td>\n","      <td>0.539600</td>\n","    </tr>\n","    <tr>\n","      <td>2880</td>\n","      <td>0.572200</td>\n","    </tr>\n","    <tr>\n","      <td>2890</td>\n","      <td>0.603200</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.593000</td>\n","    </tr>\n","    <tr>\n","      <td>2910</td>\n","      <td>0.586500</td>\n","    </tr>\n","    <tr>\n","      <td>2920</td>\n","      <td>0.568600</td>\n","    </tr>\n","    <tr>\n","      <td>2930</td>\n","      <td>0.563000</td>\n","    </tr>\n","    <tr>\n","      <td>2940</td>\n","      <td>0.599300</td>\n","    </tr>\n","    <tr>\n","      <td>2950</td>\n","      <td>0.532900</td>\n","    </tr>\n","    <tr>\n","      <td>2960</td>\n","      <td>0.605400</td>\n","    </tr>\n","    <tr>\n","      <td>2970</td>\n","      <td>0.614800</td>\n","    </tr>\n","    <tr>\n","      <td>2980</td>\n","      <td>0.568700</td>\n","    </tr>\n","    <tr>\n","      <td>2990</td>\n","      <td>0.572600</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.494000</td>\n","    </tr>\n","    <tr>\n","      <td>3010</td>\n","      <td>0.532700</td>\n","    </tr>\n","    <tr>\n","      <td>3020</td>\n","      <td>0.575200</td>\n","    </tr>\n","    <tr>\n","      <td>3030</td>\n","      <td>0.614000</td>\n","    </tr>\n","    <tr>\n","      <td>3040</td>\n","      <td>0.626100</td>\n","    </tr>\n","    <tr>\n","      <td>3050</td>\n","      <td>0.565700</td>\n","    </tr>\n","    <tr>\n","      <td>3060</td>\n","      <td>0.541800</td>\n","    </tr>\n","    <tr>\n","      <td>3070</td>\n","      <td>0.577200</td>\n","    </tr>\n","    <tr>\n","      <td>3080</td>\n","      <td>0.631200</td>\n","    </tr>\n","    <tr>\n","      <td>3090</td>\n","      <td>0.582200</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.578300</td>\n","    </tr>\n","    <tr>\n","      <td>3110</td>\n","      <td>0.617200</td>\n","    </tr>\n","    <tr>\n","      <td>3120</td>\n","      <td>0.506800</td>\n","    </tr>\n","    <tr>\n","      <td>3130</td>\n","      <td>0.579200</td>\n","    </tr>\n","    <tr>\n","      <td>3140</td>\n","      <td>0.547700</td>\n","    </tr>\n","    <tr>\n","      <td>3150</td>\n","      <td>0.555100</td>\n","    </tr>\n","    <tr>\n","      <td>3160</td>\n","      <td>0.551700</td>\n","    </tr>\n","    <tr>\n","      <td>3170</td>\n","      <td>0.630400</td>\n","    </tr>\n","    <tr>\n","      <td>3180</td>\n","      <td>0.519400</td>\n","    </tr>\n","    <tr>\n","      <td>3190</td>\n","      <td>0.575600</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.619500</td>\n","    </tr>\n","    <tr>\n","      <td>3210</td>\n","      <td>0.558300</td>\n","    </tr>\n","    <tr>\n","      <td>3220</td>\n","      <td>0.521000</td>\n","    </tr>\n","    <tr>\n","      <td>3230</td>\n","      <td>0.540400</td>\n","    </tr>\n","    <tr>\n","      <td>3240</td>\n","      <td>0.629500</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.607400</td>\n","    </tr>\n","    <tr>\n","      <td>3260</td>\n","      <td>0.643700</td>\n","    </tr>\n","    <tr>\n","      <td>3270</td>\n","      <td>0.510900</td>\n","    </tr>\n","    <tr>\n","      <td>3280</td>\n","      <td>0.562600</td>\n","    </tr>\n","    <tr>\n","      <td>3290</td>\n","      <td>0.619100</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>0.554100</td>\n","    </tr>\n","    <tr>\n","      <td>3310</td>\n","      <td>0.544200</td>\n","    </tr>\n","    <tr>\n","      <td>3320</td>\n","      <td>0.532700</td>\n","    </tr>\n","    <tr>\n","      <td>3330</td>\n","      <td>0.592700</td>\n","    </tr>\n","    <tr>\n","      <td>3340</td>\n","      <td>0.563100</td>\n","    </tr>\n","    <tr>\n","      <td>3350</td>\n","      <td>0.621400</td>\n","    </tr>\n","    <tr>\n","      <td>3360</td>\n","      <td>0.610500</td>\n","    </tr>\n","    <tr>\n","      <td>3370</td>\n","      <td>0.549000</td>\n","    </tr>\n","    <tr>\n","      <td>3380</td>\n","      <td>0.575200</td>\n","    </tr>\n","    <tr>\n","      <td>3390</td>\n","      <td>0.604600</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>0.512300</td>\n","    </tr>\n","    <tr>\n","      <td>3410</td>\n","      <td>0.521200</td>\n","    </tr>\n","    <tr>\n","      <td>3420</td>\n","      <td>0.584400</td>\n","    </tr>\n","    <tr>\n","      <td>3430</td>\n","      <td>0.578200</td>\n","    </tr>\n","    <tr>\n","      <td>3440</td>\n","      <td>0.523000</td>\n","    </tr>\n","    <tr>\n","      <td>3450</td>\n","      <td>0.529100</td>\n","    </tr>\n","    <tr>\n","      <td>3460</td>\n","      <td>0.502000</td>\n","    </tr>\n","    <tr>\n","      <td>3470</td>\n","      <td>0.532200</td>\n","    </tr>\n","    <tr>\n","      <td>3480</td>\n","      <td>0.526300</td>\n","    </tr>\n","    <tr>\n","      <td>3490</td>\n","      <td>0.535600</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.610900</td>\n","    </tr>\n","    <tr>\n","      <td>3510</td>\n","      <td>0.589400</td>\n","    </tr>\n","    <tr>\n","      <td>3520</td>\n","      <td>0.531600</td>\n","    </tr>\n","    <tr>\n","      <td>3530</td>\n","      <td>0.594400</td>\n","    </tr>\n","    <tr>\n","      <td>3540</td>\n","      <td>0.577400</td>\n","    </tr>\n","    <tr>\n","      <td>3550</td>\n","      <td>0.618900</td>\n","    </tr>\n","    <tr>\n","      <td>3560</td>\n","      <td>0.588900</td>\n","    </tr>\n","    <tr>\n","      <td>3570</td>\n","      <td>0.588000</td>\n","    </tr>\n","    <tr>\n","      <td>3580</td>\n","      <td>0.553400</td>\n","    </tr>\n","    <tr>\n","      <td>3590</td>\n","      <td>0.579300</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.588400</td>\n","    </tr>\n","    <tr>\n","      <td>3610</td>\n","      <td>0.494800</td>\n","    </tr>\n","    <tr>\n","      <td>3620</td>\n","      <td>0.605800</td>\n","    </tr>\n","    <tr>\n","      <td>3630</td>\n","      <td>0.616300</td>\n","    </tr>\n","    <tr>\n","      <td>3640</td>\n","      <td>0.568500</td>\n","    </tr>\n","    <tr>\n","      <td>3650</td>\n","      <td>0.580400</td>\n","    </tr>\n","    <tr>\n","      <td>3660</td>\n","      <td>0.586100</td>\n","    </tr>\n","    <tr>\n","      <td>3670</td>\n","      <td>0.606300</td>\n","    </tr>\n","    <tr>\n","      <td>3680</td>\n","      <td>0.537100</td>\n","    </tr>\n","    <tr>\n","      <td>3690</td>\n","      <td>0.586100</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>0.578200</td>\n","    </tr>\n","    <tr>\n","      <td>3710</td>\n","      <td>0.585100</td>\n","    </tr>\n","    <tr>\n","      <td>3720</td>\n","      <td>0.574800</td>\n","    </tr>\n","    <tr>\n","      <td>3730</td>\n","      <td>0.605400</td>\n","    </tr>\n","    <tr>\n","      <td>3740</td>\n","      <td>0.554300</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>0.627400</td>\n","    </tr>\n","    <tr>\n","      <td>3760</td>\n","      <td>0.603600</td>\n","    </tr>\n","    <tr>\n","      <td>3770</td>\n","      <td>0.571400</td>\n","    </tr>\n","    <tr>\n","      <td>3780</td>\n","      <td>0.562700</td>\n","    </tr>\n","    <tr>\n","      <td>3790</td>\n","      <td>0.608800</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>0.548100</td>\n","    </tr>\n","    <tr>\n","      <td>3810</td>\n","      <td>0.599700</td>\n","    </tr>\n","    <tr>\n","      <td>3820</td>\n","      <td>0.632100</td>\n","    </tr>\n","    <tr>\n","      <td>3830</td>\n","      <td>0.585600</td>\n","    </tr>\n","    <tr>\n","      <td>3840</td>\n","      <td>0.519500</td>\n","    </tr>\n","    <tr>\n","      <td>3850</td>\n","      <td>0.563400</td>\n","    </tr>\n","    <tr>\n","      <td>3860</td>\n","      <td>0.600700</td>\n","    </tr>\n","    <tr>\n","      <td>3870</td>\n","      <td>0.577300</td>\n","    </tr>\n","    <tr>\n","      <td>3880</td>\n","      <td>0.607600</td>\n","    </tr>\n","    <tr>\n","      <td>3890</td>\n","      <td>0.522600</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>0.513700</td>\n","    </tr>\n","    <tr>\n","      <td>3910</td>\n","      <td>0.598800</td>\n","    </tr>\n","    <tr>\n","      <td>3920</td>\n","      <td>0.624800</td>\n","    </tr>\n","    <tr>\n","      <td>3930</td>\n","      <td>0.583500</td>\n","    </tr>\n","    <tr>\n","      <td>3940</td>\n","      <td>0.609000</td>\n","    </tr>\n","    <tr>\n","      <td>3950</td>\n","      <td>0.538400</td>\n","    </tr>\n","    <tr>\n","      <td>3960</td>\n","      <td>0.603800</td>\n","    </tr>\n","    <tr>\n","      <td>3970</td>\n","      <td>0.529700</td>\n","    </tr>\n","    <tr>\n","      <td>3980</td>\n","      <td>0.623900</td>\n","    </tr>\n","    <tr>\n","      <td>3990</td>\n","      <td>0.588800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.580500</td>\n","    </tr>\n","    <tr>\n","      <td>4010</td>\n","      <td>0.613800</td>\n","    </tr>\n","    <tr>\n","      <td>4020</td>\n","      <td>0.553100</td>\n","    </tr>\n","    <tr>\n","      <td>4030</td>\n","      <td>0.611100</td>\n","    </tr>\n","    <tr>\n","      <td>4040</td>\n","      <td>0.569500</td>\n","    </tr>\n","    <tr>\n","      <td>4050</td>\n","      <td>0.559800</td>\n","    </tr>\n","    <tr>\n","      <td>4060</td>\n","      <td>0.603500</td>\n","    </tr>\n","    <tr>\n","      <td>4070</td>\n","      <td>0.548100</td>\n","    </tr>\n","    <tr>\n","      <td>4080</td>\n","      <td>0.580200</td>\n","    </tr>\n","    <tr>\n","      <td>4090</td>\n","      <td>0.604400</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>0.609000</td>\n","    </tr>\n","    <tr>\n","      <td>4110</td>\n","      <td>0.562400</td>\n","    </tr>\n","    <tr>\n","      <td>4120</td>\n","      <td>0.569600</td>\n","    </tr>\n","    <tr>\n","      <td>4130</td>\n","      <td>0.626800</td>\n","    </tr>\n","    <tr>\n","      <td>4140</td>\n","      <td>0.592900</td>\n","    </tr>\n","    <tr>\n","      <td>4150</td>\n","      <td>0.578500</td>\n","    </tr>\n","    <tr>\n","      <td>4160</td>\n","      <td>0.496600</td>\n","    </tr>\n","    <tr>\n","      <td>4170</td>\n","      <td>0.556800</td>\n","    </tr>\n","    <tr>\n","      <td>4180</td>\n","      <td>0.584300</td>\n","    </tr>\n","    <tr>\n","      <td>4190</td>\n","      <td>0.596300</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>0.584400</td>\n","    </tr>\n","    <tr>\n","      <td>4210</td>\n","      <td>0.532400</td>\n","    </tr>\n","    <tr>\n","      <td>4220</td>\n","      <td>0.585100</td>\n","    </tr>\n","    <tr>\n","      <td>4230</td>\n","      <td>0.589700</td>\n","    </tr>\n","    <tr>\n","      <td>4240</td>\n","      <td>0.641500</td>\n","    </tr>\n","    <tr>\n","      <td>4250</td>\n","      <td>0.530400</td>\n","    </tr>\n","    <tr>\n","      <td>4260</td>\n","      <td>0.652700</td>\n","    </tr>\n","    <tr>\n","      <td>4270</td>\n","      <td>0.618000</td>\n","    </tr>\n","    <tr>\n","      <td>4280</td>\n","      <td>0.609800</td>\n","    </tr>\n","    <tr>\n","      <td>4290</td>\n","      <td>0.586900</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>0.626000</td>\n","    </tr>\n","    <tr>\n","      <td>4310</td>\n","      <td>0.580700</td>\n","    </tr>\n","    <tr>\n","      <td>4320</td>\n","      <td>0.593500</td>\n","    </tr>\n","    <tr>\n","      <td>4330</td>\n","      <td>0.551100</td>\n","    </tr>\n","    <tr>\n","      <td>4340</td>\n","      <td>0.561100</td>\n","    </tr>\n","    <tr>\n","      <td>4350</td>\n","      <td>0.604700</td>\n","    </tr>\n","    <tr>\n","      <td>4360</td>\n","      <td>0.615900</td>\n","    </tr>\n","    <tr>\n","      <td>4370</td>\n","      <td>0.533100</td>\n","    </tr>\n","    <tr>\n","      <td>4380</td>\n","      <td>0.564200</td>\n","    </tr>\n","    <tr>\n","      <td>4390</td>\n","      <td>0.565000</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>0.523300</td>\n","    </tr>\n","    <tr>\n","      <td>4410</td>\n","      <td>0.577000</td>\n","    </tr>\n","    <tr>\n","      <td>4420</td>\n","      <td>0.618600</td>\n","    </tr>\n","    <tr>\n","      <td>4430</td>\n","      <td>0.537100</td>\n","    </tr>\n","    <tr>\n","      <td>4440</td>\n","      <td>0.582800</td>\n","    </tr>\n","    <tr>\n","      <td>4450</td>\n","      <td>0.557700</td>\n","    </tr>\n","    <tr>\n","      <td>4460</td>\n","      <td>0.568100</td>\n","    </tr>\n","    <tr>\n","      <td>4470</td>\n","      <td>0.603300</td>\n","    </tr>\n","    <tr>\n","      <td>4480</td>\n","      <td>0.560100</td>\n","    </tr>\n","    <tr>\n","      <td>4490</td>\n","      <td>0.579700</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.590400</td>\n","    </tr>\n","    <tr>\n","      <td>4510</td>\n","      <td>0.606300</td>\n","    </tr>\n","    <tr>\n","      <td>4520</td>\n","      <td>0.589800</td>\n","    </tr>\n","    <tr>\n","      <td>4530</td>\n","      <td>0.559600</td>\n","    </tr>\n","    <tr>\n","      <td>4540</td>\n","      <td>0.594000</td>\n","    </tr>\n","    <tr>\n","      <td>4550</td>\n","      <td>0.532300</td>\n","    </tr>\n","    <tr>\n","      <td>4560</td>\n","      <td>0.581800</td>\n","    </tr>\n","    <tr>\n","      <td>4570</td>\n","      <td>0.524500</td>\n","    </tr>\n","    <tr>\n","      <td>4580</td>\n","      <td>0.560400</td>\n","    </tr>\n","    <tr>\n","      <td>4590</td>\n","      <td>0.588800</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>0.548100</td>\n","    </tr>\n","    <tr>\n","      <td>4610</td>\n","      <td>0.623500</td>\n","    </tr>\n","    <tr>\n","      <td>4620</td>\n","      <td>0.536200</td>\n","    </tr>\n","    <tr>\n","      <td>4630</td>\n","      <td>0.551100</td>\n","    </tr>\n","    <tr>\n","      <td>4640</td>\n","      <td>0.545000</td>\n","    </tr>\n","    <tr>\n","      <td>4650</td>\n","      <td>0.602700</td>\n","    </tr>\n","    <tr>\n","      <td>4660</td>\n","      <td>0.602500</td>\n","    </tr>\n","    <tr>\n","      <td>4670</td>\n","      <td>0.588300</td>\n","    </tr>\n","    <tr>\n","      <td>4680</td>\n","      <td>0.526100</td>\n","    </tr>\n","    <tr>\n","      <td>4690</td>\n","      <td>0.594700</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>0.551200</td>\n","    </tr>\n","    <tr>\n","      <td>4710</td>\n","      <td>0.507700</td>\n","    </tr>\n","    <tr>\n","      <td>4720</td>\n","      <td>0.551100</td>\n","    </tr>\n","    <tr>\n","      <td>4730</td>\n","      <td>0.600100</td>\n","    </tr>\n","    <tr>\n","      <td>4740</td>\n","      <td>0.490900</td>\n","    </tr>\n","    <tr>\n","      <td>4750</td>\n","      <td>0.517800</td>\n","    </tr>\n","    <tr>\n","      <td>4760</td>\n","      <td>0.541700</td>\n","    </tr>\n","    <tr>\n","      <td>4770</td>\n","      <td>0.572600</td>\n","    </tr>\n","    <tr>\n","      <td>4780</td>\n","      <td>0.550700</td>\n","    </tr>\n","    <tr>\n","      <td>4790</td>\n","      <td>0.608000</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>0.558900</td>\n","    </tr>\n","    <tr>\n","      <td>4810</td>\n","      <td>0.589100</td>\n","    </tr>\n","    <tr>\n","      <td>4820</td>\n","      <td>0.529100</td>\n","    </tr>\n","    <tr>\n","      <td>4830</td>\n","      <td>0.476300</td>\n","    </tr>\n","    <tr>\n","      <td>4840</td>\n","      <td>0.482200</td>\n","    </tr>\n","    <tr>\n","      <td>4850</td>\n","      <td>0.578100</td>\n","    </tr>\n","    <tr>\n","      <td>4860</td>\n","      <td>0.558000</td>\n","    </tr>\n","    <tr>\n","      <td>4870</td>\n","      <td>0.561800</td>\n","    </tr>\n","    <tr>\n","      <td>4880</td>\n","      <td>0.516900</td>\n","    </tr>\n","    <tr>\n","      <td>4890</td>\n","      <td>0.484600</td>\n","    </tr>\n","    <tr>\n","      <td>4900</td>\n","      <td>0.633800</td>\n","    </tr>\n","    <tr>\n","      <td>4910</td>\n","      <td>0.585600</td>\n","    </tr>\n","    <tr>\n","      <td>4920</td>\n","      <td>0.531700</td>\n","    </tr>\n","    <tr>\n","      <td>4930</td>\n","      <td>0.610400</td>\n","    </tr>\n","    <tr>\n","      <td>4940</td>\n","      <td>0.502200</td>\n","    </tr>\n","    <tr>\n","      <td>4950</td>\n","      <td>0.586200</td>\n","    </tr>\n","    <tr>\n","      <td>4960</td>\n","      <td>0.552700</td>\n","    </tr>\n","    <tr>\n","      <td>4970</td>\n","      <td>0.508300</td>\n","    </tr>\n","    <tr>\n","      <td>4980</td>\n","      <td>0.525400</td>\n","    </tr>\n","    <tr>\n","      <td>4990</td>\n","      <td>0.572000</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.581300</td>\n","    </tr>\n","    <tr>\n","      <td>5010</td>\n","      <td>0.485400</td>\n","    </tr>\n","    <tr>\n","      <td>5020</td>\n","      <td>0.588000</td>\n","    </tr>\n","    <tr>\n","      <td>5030</td>\n","      <td>0.529600</td>\n","    </tr>\n","    <tr>\n","      <td>5040</td>\n","      <td>0.611000</td>\n","    </tr>\n","    <tr>\n","      <td>5050</td>\n","      <td>0.481700</td>\n","    </tr>\n","    <tr>\n","      <td>5060</td>\n","      <td>0.530600</td>\n","    </tr>\n","    <tr>\n","      <td>5070</td>\n","      <td>0.571900</td>\n","    </tr>\n","    <tr>\n","      <td>5080</td>\n","      <td>0.516200</td>\n","    </tr>\n","    <tr>\n","      <td>5090</td>\n","      <td>0.609300</td>\n","    </tr>\n","    <tr>\n","      <td>5100</td>\n","      <td>0.423400</td>\n","    </tr>\n","    <tr>\n","      <td>5110</td>\n","      <td>0.543200</td>\n","    </tr>\n","    <tr>\n","      <td>5120</td>\n","      <td>0.458300</td>\n","    </tr>\n","    <tr>\n","      <td>5130</td>\n","      <td>0.633100</td>\n","    </tr>\n","    <tr>\n","      <td>5140</td>\n","      <td>0.433500</td>\n","    </tr>\n","    <tr>\n","      <td>5150</td>\n","      <td>0.566200</td>\n","    </tr>\n","    <tr>\n","      <td>5160</td>\n","      <td>0.553100</td>\n","    </tr>\n","    <tr>\n","      <td>5170</td>\n","      <td>0.551800</td>\n","    </tr>\n","    <tr>\n","      <td>5180</td>\n","      <td>0.557400</td>\n","    </tr>\n","    <tr>\n","      <td>5190</td>\n","      <td>0.514500</td>\n","    </tr>\n","    <tr>\n","      <td>5200</td>\n","      <td>0.530300</td>\n","    </tr>\n","    <tr>\n","      <td>5210</td>\n","      <td>0.595400</td>\n","    </tr>\n","    <tr>\n","      <td>5220</td>\n","      <td>0.505600</td>\n","    </tr>\n","    <tr>\n","      <td>5230</td>\n","      <td>0.520800</td>\n","    </tr>\n","    <tr>\n","      <td>5240</td>\n","      <td>0.508600</td>\n","    </tr>\n","    <tr>\n","      <td>5250</td>\n","      <td>0.620500</td>\n","    </tr>\n","    <tr>\n","      <td>5260</td>\n","      <td>0.505800</td>\n","    </tr>\n","    <tr>\n","      <td>5270</td>\n","      <td>0.580000</td>\n","    </tr>\n","    <tr>\n","      <td>5280</td>\n","      <td>0.563400</td>\n","    </tr>\n","    <tr>\n","      <td>5290</td>\n","      <td>0.506000</td>\n","    </tr>\n","    <tr>\n","      <td>5300</td>\n","      <td>0.489600</td>\n","    </tr>\n","    <tr>\n","      <td>5310</td>\n","      <td>0.580900</td>\n","    </tr>\n","    <tr>\n","      <td>5320</td>\n","      <td>0.512000</td>\n","    </tr>\n","    <tr>\n","      <td>5330</td>\n","      <td>0.549300</td>\n","    </tr>\n","    <tr>\n","      <td>5340</td>\n","      <td>0.558500</td>\n","    </tr>\n","    <tr>\n","      <td>5350</td>\n","      <td>0.560000</td>\n","    </tr>\n","    <tr>\n","      <td>5360</td>\n","      <td>0.517600</td>\n","    </tr>\n","    <tr>\n","      <td>5370</td>\n","      <td>0.569700</td>\n","    </tr>\n","    <tr>\n","      <td>5380</td>\n","      <td>0.533200</td>\n","    </tr>\n","    <tr>\n","      <td>5390</td>\n","      <td>0.528500</td>\n","    </tr>\n","    <tr>\n","      <td>5400</td>\n","      <td>0.561500</td>\n","    </tr>\n","    <tr>\n","      <td>5410</td>\n","      <td>0.509300</td>\n","    </tr>\n","    <tr>\n","      <td>5420</td>\n","      <td>0.480900</td>\n","    </tr>\n","    <tr>\n","      <td>5430</td>\n","      <td>0.523900</td>\n","    </tr>\n","    <tr>\n","      <td>5440</td>\n","      <td>0.503200</td>\n","    </tr>\n","    <tr>\n","      <td>5450</td>\n","      <td>0.569200</td>\n","    </tr>\n","    <tr>\n","      <td>5460</td>\n","      <td>0.519000</td>\n","    </tr>\n","    <tr>\n","      <td>5470</td>\n","      <td>0.559900</td>\n","    </tr>\n","    <tr>\n","      <td>5480</td>\n","      <td>0.501800</td>\n","    </tr>\n","    <tr>\n","      <td>5490</td>\n","      <td>0.659600</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.501800</td>\n","    </tr>\n","    <tr>\n","      <td>5510</td>\n","      <td>0.548600</td>\n","    </tr>\n","    <tr>\n","      <td>5520</td>\n","      <td>0.578200</td>\n","    </tr>\n","    <tr>\n","      <td>5530</td>\n","      <td>0.521600</td>\n","    </tr>\n","    <tr>\n","      <td>5540</td>\n","      <td>0.508300</td>\n","    </tr>\n","    <tr>\n","      <td>5550</td>\n","      <td>0.621000</td>\n","    </tr>\n","    <tr>\n","      <td>5560</td>\n","      <td>0.573700</td>\n","    </tr>\n","    <tr>\n","      <td>5570</td>\n","      <td>0.455700</td>\n","    </tr>\n","    <tr>\n","      <td>5580</td>\n","      <td>0.569000</td>\n","    </tr>\n","    <tr>\n","      <td>5590</td>\n","      <td>0.502700</td>\n","    </tr>\n","    <tr>\n","      <td>5600</td>\n","      <td>0.549300</td>\n","    </tr>\n","    <tr>\n","      <td>5610</td>\n","      <td>0.528800</td>\n","    </tr>\n","    <tr>\n","      <td>5620</td>\n","      <td>0.514800</td>\n","    </tr>\n","    <tr>\n","      <td>5630</td>\n","      <td>0.479400</td>\n","    </tr>\n","    <tr>\n","      <td>5640</td>\n","      <td>0.670100</td>\n","    </tr>\n","    <tr>\n","      <td>5650</td>\n","      <td>0.562400</td>\n","    </tr>\n","    <tr>\n","      <td>5660</td>\n","      <td>0.525600</td>\n","    </tr>\n","    <tr>\n","      <td>5670</td>\n","      <td>0.504600</td>\n","    </tr>\n","    <tr>\n","      <td>5680</td>\n","      <td>0.561300</td>\n","    </tr>\n","    <tr>\n","      <td>5690</td>\n","      <td>0.511300</td>\n","    </tr>\n","    <tr>\n","      <td>5700</td>\n","      <td>0.533000</td>\n","    </tr>\n","    <tr>\n","      <td>5710</td>\n","      <td>0.570500</td>\n","    </tr>\n","    <tr>\n","      <td>5720</td>\n","      <td>0.516200</td>\n","    </tr>\n","    <tr>\n","      <td>5730</td>\n","      <td>0.526600</td>\n","    </tr>\n","    <tr>\n","      <td>5740</td>\n","      <td>0.475600</td>\n","    </tr>\n","    <tr>\n","      <td>5750</td>\n","      <td>0.539700</td>\n","    </tr>\n","    <tr>\n","      <td>5760</td>\n","      <td>0.590400</td>\n","    </tr>\n","    <tr>\n","      <td>5770</td>\n","      <td>0.558400</td>\n","    </tr>\n","    <tr>\n","      <td>5780</td>\n","      <td>0.484600</td>\n","    </tr>\n","    <tr>\n","      <td>5790</td>\n","      <td>0.534900</td>\n","    </tr>\n","    <tr>\n","      <td>5800</td>\n","      <td>0.477700</td>\n","    </tr>\n","    <tr>\n","      <td>5810</td>\n","      <td>0.498200</td>\n","    </tr>\n","    <tr>\n","      <td>5820</td>\n","      <td>0.463500</td>\n","    </tr>\n","    <tr>\n","      <td>5830</td>\n","      <td>0.598600</td>\n","    </tr>\n","    <tr>\n","      <td>5840</td>\n","      <td>0.505700</td>\n","    </tr>\n","    <tr>\n","      <td>5850</td>\n","      <td>0.569300</td>\n","    </tr>\n","    <tr>\n","      <td>5860</td>\n","      <td>0.537600</td>\n","    </tr>\n","    <tr>\n","      <td>5870</td>\n","      <td>0.540900</td>\n","    </tr>\n","    <tr>\n","      <td>5880</td>\n","      <td>0.600300</td>\n","    </tr>\n","    <tr>\n","      <td>5890</td>\n","      <td>0.496100</td>\n","    </tr>\n","    <tr>\n","      <td>5900</td>\n","      <td>0.533900</td>\n","    </tr>\n","    <tr>\n","      <td>5910</td>\n","      <td>0.550300</td>\n","    </tr>\n","    <tr>\n","      <td>5920</td>\n","      <td>0.548700</td>\n","    </tr>\n","    <tr>\n","      <td>5930</td>\n","      <td>0.520700</td>\n","    </tr>\n","    <tr>\n","      <td>5940</td>\n","      <td>0.545900</td>\n","    </tr>\n","    <tr>\n","      <td>5950</td>\n","      <td>0.492300</td>\n","    </tr>\n","    <tr>\n","      <td>5960</td>\n","      <td>0.611500</td>\n","    </tr>\n","    <tr>\n","      <td>5970</td>\n","      <td>0.571400</td>\n","    </tr>\n","    <tr>\n","      <td>5980</td>\n","      <td>0.540400</td>\n","    </tr>\n","    <tr>\n","      <td>5990</td>\n","      <td>0.542900</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.516200</td>\n","    </tr>\n","    <tr>\n","      <td>6010</td>\n","      <td>0.520900</td>\n","    </tr>\n","    <tr>\n","      <td>6020</td>\n","      <td>0.442800</td>\n","    </tr>\n","    <tr>\n","      <td>6030</td>\n","      <td>0.502700</td>\n","    </tr>\n","    <tr>\n","      <td>6040</td>\n","      <td>0.474700</td>\n","    </tr>\n","    <tr>\n","      <td>6050</td>\n","      <td>0.579800</td>\n","    </tr>\n","    <tr>\n","      <td>6060</td>\n","      <td>0.534300</td>\n","    </tr>\n","    <tr>\n","      <td>6070</td>\n","      <td>0.469700</td>\n","    </tr>\n","    <tr>\n","      <td>6080</td>\n","      <td>0.489100</td>\n","    </tr>\n","    <tr>\n","      <td>6090</td>\n","      <td>0.534000</td>\n","    </tr>\n","    <tr>\n","      <td>6100</td>\n","      <td>0.637500</td>\n","    </tr>\n","    <tr>\n","      <td>6110</td>\n","      <td>0.459900</td>\n","    </tr>\n","    <tr>\n","      <td>6120</td>\n","      <td>0.615600</td>\n","    </tr>\n","    <tr>\n","      <td>6130</td>\n","      <td>0.584000</td>\n","    </tr>\n","    <tr>\n","      <td>6140</td>\n","      <td>0.482400</td>\n","    </tr>\n","    <tr>\n","      <td>6150</td>\n","      <td>0.528600</td>\n","    </tr>\n","    <tr>\n","      <td>6160</td>\n","      <td>0.596900</td>\n","    </tr>\n","    <tr>\n","      <td>6170</td>\n","      <td>0.509800</td>\n","    </tr>\n","    <tr>\n","      <td>6180</td>\n","      <td>0.505400</td>\n","    </tr>\n","    <tr>\n","      <td>6190</td>\n","      <td>0.611600</td>\n","    </tr>\n","    <tr>\n","      <td>6200</td>\n","      <td>0.528100</td>\n","    </tr>\n","    <tr>\n","      <td>6210</td>\n","      <td>0.464300</td>\n","    </tr>\n","    <tr>\n","      <td>6220</td>\n","      <td>0.600600</td>\n","    </tr>\n","    <tr>\n","      <td>6230</td>\n","      <td>0.572200</td>\n","    </tr>\n","    <tr>\n","      <td>6240</td>\n","      <td>0.600100</td>\n","    </tr>\n","    <tr>\n","      <td>6250</td>\n","      <td>0.539200</td>\n","    </tr>\n","    <tr>\n","      <td>6260</td>\n","      <td>0.552100</td>\n","    </tr>\n","    <tr>\n","      <td>6270</td>\n","      <td>0.532800</td>\n","    </tr>\n","    <tr>\n","      <td>6280</td>\n","      <td>0.498600</td>\n","    </tr>\n","    <tr>\n","      <td>6290</td>\n","      <td>0.562900</td>\n","    </tr>\n","    <tr>\n","      <td>6300</td>\n","      <td>0.562800</td>\n","    </tr>\n","    <tr>\n","      <td>6310</td>\n","      <td>0.496900</td>\n","    </tr>\n","    <tr>\n","      <td>6320</td>\n","      <td>0.558300</td>\n","    </tr>\n","    <tr>\n","      <td>6330</td>\n","      <td>0.564400</td>\n","    </tr>\n","    <tr>\n","      <td>6340</td>\n","      <td>0.593800</td>\n","    </tr>\n","    <tr>\n","      <td>6350</td>\n","      <td>0.532800</td>\n","    </tr>\n","    <tr>\n","      <td>6360</td>\n","      <td>0.568700</td>\n","    </tr>\n","    <tr>\n","      <td>6370</td>\n","      <td>0.594400</td>\n","    </tr>\n","    <tr>\n","      <td>6380</td>\n","      <td>0.531400</td>\n","    </tr>\n","    <tr>\n","      <td>6390</td>\n","      <td>0.580900</td>\n","    </tr>\n","    <tr>\n","      <td>6400</td>\n","      <td>0.497000</td>\n","    </tr>\n","    <tr>\n","      <td>6410</td>\n","      <td>0.471300</td>\n","    </tr>\n","    <tr>\n","      <td>6420</td>\n","      <td>0.498300</td>\n","    </tr>\n","    <tr>\n","      <td>6430</td>\n","      <td>0.498900</td>\n","    </tr>\n","    <tr>\n","      <td>6440</td>\n","      <td>0.496400</td>\n","    </tr>\n","    <tr>\n","      <td>6450</td>\n","      <td>0.502900</td>\n","    </tr>\n","    <tr>\n","      <td>6460</td>\n","      <td>0.594300</td>\n","    </tr>\n","    <tr>\n","      <td>6470</td>\n","      <td>0.543700</td>\n","    </tr>\n","    <tr>\n","      <td>6480</td>\n","      <td>0.587300</td>\n","    </tr>\n","    <tr>\n","      <td>6490</td>\n","      <td>0.483000</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.557500</td>\n","    </tr>\n","    <tr>\n","      <td>6510</td>\n","      <td>0.424500</td>\n","    </tr>\n","    <tr>\n","      <td>6520</td>\n","      <td>0.568800</td>\n","    </tr>\n","    <tr>\n","      <td>6530</td>\n","      <td>0.571100</td>\n","    </tr>\n","    <tr>\n","      <td>6540</td>\n","      <td>0.509600</td>\n","    </tr>\n","    <tr>\n","      <td>6550</td>\n","      <td>0.622000</td>\n","    </tr>\n","    <tr>\n","      <td>6560</td>\n","      <td>0.533100</td>\n","    </tr>\n","    <tr>\n","      <td>6570</td>\n","      <td>0.567400</td>\n","    </tr>\n","    <tr>\n","      <td>6580</td>\n","      <td>0.605900</td>\n","    </tr>\n","    <tr>\n","      <td>6590</td>\n","      <td>0.516800</td>\n","    </tr>\n","    <tr>\n","      <td>6600</td>\n","      <td>0.495000</td>\n","    </tr>\n","    <tr>\n","      <td>6610</td>\n","      <td>0.543300</td>\n","    </tr>\n","    <tr>\n","      <td>6620</td>\n","      <td>0.570600</td>\n","    </tr>\n","    <tr>\n","      <td>6630</td>\n","      <td>0.513900</td>\n","    </tr>\n","    <tr>\n","      <td>6640</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>6650</td>\n","      <td>0.516800</td>\n","    </tr>\n","    <tr>\n","      <td>6660</td>\n","      <td>0.572800</td>\n","    </tr>\n","    <tr>\n","      <td>6670</td>\n","      <td>0.619100</td>\n","    </tr>\n","    <tr>\n","      <td>6680</td>\n","      <td>0.554700</td>\n","    </tr>\n","    <tr>\n","      <td>6690</td>\n","      <td>0.561400</td>\n","    </tr>\n","    <tr>\n","      <td>6700</td>\n","      <td>0.542300</td>\n","    </tr>\n","    <tr>\n","      <td>6710</td>\n","      <td>0.560500</td>\n","    </tr>\n","    <tr>\n","      <td>6720</td>\n","      <td>0.478800</td>\n","    </tr>\n","    <tr>\n","      <td>6730</td>\n","      <td>0.561900</td>\n","    </tr>\n","    <tr>\n","      <td>6740</td>\n","      <td>0.525200</td>\n","    </tr>\n","    <tr>\n","      <td>6750</td>\n","      <td>0.486400</td>\n","    </tr>\n","    <tr>\n","      <td>6760</td>\n","      <td>0.551200</td>\n","    </tr>\n","    <tr>\n","      <td>6770</td>\n","      <td>0.570200</td>\n","    </tr>\n","    <tr>\n","      <td>6780</td>\n","      <td>0.490500</td>\n","    </tr>\n","    <tr>\n","      <td>6790</td>\n","      <td>0.497300</td>\n","    </tr>\n","    <tr>\n","      <td>6800</td>\n","      <td>0.519100</td>\n","    </tr>\n","    <tr>\n","      <td>6810</td>\n","      <td>0.463400</td>\n","    </tr>\n","    <tr>\n","      <td>6820</td>\n","      <td>0.528700</td>\n","    </tr>\n","    <tr>\n","      <td>6830</td>\n","      <td>0.513700</td>\n","    </tr>\n","    <tr>\n","      <td>6840</td>\n","      <td>0.539600</td>\n","    </tr>\n","    <tr>\n","      <td>6850</td>\n","      <td>0.512100</td>\n","    </tr>\n","    <tr>\n","      <td>6860</td>\n","      <td>0.500200</td>\n","    </tr>\n","    <tr>\n","      <td>6870</td>\n","      <td>0.580200</td>\n","    </tr>\n","    <tr>\n","      <td>6880</td>\n","      <td>0.491000</td>\n","    </tr>\n","    <tr>\n","      <td>6890</td>\n","      <td>0.542200</td>\n","    </tr>\n","    <tr>\n","      <td>6900</td>\n","      <td>0.554900</td>\n","    </tr>\n","    <tr>\n","      <td>6910</td>\n","      <td>0.499700</td>\n","    </tr>\n","    <tr>\n","      <td>6920</td>\n","      <td>0.614900</td>\n","    </tr>\n","    <tr>\n","      <td>6930</td>\n","      <td>0.503200</td>\n","    </tr>\n","    <tr>\n","      <td>6940</td>\n","      <td>0.524500</td>\n","    </tr>\n","    <tr>\n","      <td>6950</td>\n","      <td>0.552900</td>\n","    </tr>\n","    <tr>\n","      <td>6960</td>\n","      <td>0.529200</td>\n","    </tr>\n","    <tr>\n","      <td>6970</td>\n","      <td>0.472700</td>\n","    </tr>\n","    <tr>\n","      <td>6980</td>\n","      <td>0.510000</td>\n","    </tr>\n","    <tr>\n","      <td>6990</td>\n","      <td>0.461800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.502300</td>\n","    </tr>\n","    <tr>\n","      <td>7010</td>\n","      <td>0.495600</td>\n","    </tr>\n","    <tr>\n","      <td>7020</td>\n","      <td>0.569000</td>\n","    </tr>\n","    <tr>\n","      <td>7030</td>\n","      <td>0.538700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=7032, training_loss=0.5734468095080845, metrics={'train_runtime': 2592.8517, 'train_samples_per_second': 43.38, 'train_steps_per_second': 2.712, 'total_flos': 7398617098959360.0, 'train_loss': 0.5734468095080845, 'epoch': 3.0})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Train model\n","trainer.train()"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":66672,"status":"ok","timestamp":1717892729773,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"GOBq7dxSNKxr","outputId":"76013a96-6b25-4448-c0cc-62ad02bc07b3"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='586' max='586' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [586/586 01:06]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.6024132966995239, 'eval_runtime': 66.7705, 'eval_samples_per_second': 140.391, 'eval_steps_per_second': 8.776, 'epoch': 3.0}\n"]}],"source":["# Evaluate model\n","results = trainer.evaluate()\n","print(results)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":362,"status":"error","timestamp":1717893853295,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"_4bX5NTna6VB","outputId":"4c991111-4828-4944-fa7a-8d230d7c220a"},"outputs":[{"ename":"AttributeError","evalue":"'CallbackHandler' object has no attribute 'log_history'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-dbbacabcd768>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get the training logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Extract the training loss from the logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'CallbackHandler' object has no attribute 'log_history'"]}],"source":["#import matplotlib.pyplot as plt\n","\n","# Get the training logs\n","# train_logs = trainer.callback_handler.log_history\n","\n","# Extract the training loss from the logs\n","# train_loss = [log[\"loss\"] for log in train_logs if \"loss\" in log]\n","\n","# Plot the training loss\n","# plt.plot(train_loss, label=\"Training Loss\")\n","# plt.xlabel(\"Epoch\")\n","# plt.ylabel(\"Loss\")\n","# plt.title(\"Training Loss Over Epochs\")\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":2790,"status":"ok","timestamp":1717893038047,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"dSum0NIuZqyr"},"outputs":[],"source":["# Save model pretrained model for hugging face\n","model.save_pretrained(\"D:\\Project\\Final Project Indonesia AI/01_09062024_bert_sentiment_model\", from_pt=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save_model('D:\\Project\\Final Project Indonesia AI')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1NrXK-csKIFf"},"outputs":[],"source":["!pip install"]},{"cell_type":"markdown","metadata":{"id":"nSsqQg7Pj7Vc"},"source":["## testing the fine tuned models!"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304,"referenced_widgets":["672cd94584ab4150b44715ef793212da","f4dd87a5c6794b65ad6b521b1785f0c7","3089b6978c4f422eb6f50da8a783a6a0","f5404cd32ac34cf1aa0c76018c82d124","943a2deec10e45fb8f6798b0fdfb6db9","41ac6c0a38614bc98c3fc989d22f13ac","85c036d23fbb484d9c332347138ccd33","bb0f0fc66d174950baecd017cc026433","d2c0edfd5782428cb5b12a1c31842bcb","eb337219fe6d4683a2372f1b589021ec","de60dfcbba0e4ac2a1014db8937976fb","e843a8800b6e42de9e5419df0d9d2eab","c8e880ce1c3c42dabcfff424d84c74bb","5f1fbfd0fccf4f20bf8a53d56a07aaf4","00fd29a8fbd54e1fa1575a8057ce20cf","63042bbc8e114aefa2569fdb6c412a6d","d29a04973ea246dc94095f0dd4394009","64e2a92dc167485daefc082eaab58ded","9c3f9fac3bfe4f29ae90bcb675764934","89de5a5d3705416bb0d9ff3793c8d66d","3a266cc6ea9041d09b238a5481a0dee3","d6f3a38738c8483cbc49409ca80e3f00","b584a642800a4227a67f5f5ef5598d83","db82d79f2c124a90b2918c4dfc8b88fe","0ab896d37b3e4fbeac970a84426d1dbc","04ab51d54ef64aa5afa1a01ad51f9e96","214e9bf70436439a90fb7001c8a4545b","bc5b3fea4bcd4a2cb8748d2e616b6946","59b23f47f7f14214804e78f450655eb8","35a0521f3cba4915b323e0761f6ea880","6b119b7391aa44b8896b2023a286b4e4","d0d90a99f1ac44aa99d598e69b3ac779","b1eca0741afa489ea780cc29cc4fa8b6","18582fa25f5648d4a8010f7d07cd10d9","b5f4bcc0bf78414f9c6e8617349a145e","7e58f7f4e3d643eab559496508dc6053","4cbdbc98da944ff4b0c1301dc8b393fa","c21c02c3fc4c453787cfa8db05958570","762646ebb59249289de8855f8a0f0e5b","09c35363060046c780ae96043fcb26ad","4d54f7ebfdc54b22bad28b5051661d98","21f58654e03e48d7a1dc2fdaff99239d","6cbe3c51c2b24c9791a70ed2870efe6b","c73cadac8b784228b713329aba3f0c5d"]},"executionInfo":{"elapsed":10179,"status":"ok","timestamp":1717903002585,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"HJWoV7nKXlZx","outputId":"71e1c199-f87d-404f-a4b8-d74dd9d80ec0"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"672cd94584ab4150b44715ef793212da","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e843a8800b6e42de9e5419df0d9d2eab","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b584a642800a4227a67f5f5ef5598d83","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18582fa25f5648d4a8010f7d07cd10d9","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load tokenizer and fine-tuned model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/AI FOR INDONESIA/Final Project/01_09062024_bert_sentiment_model\") # the fine tuned model save\n","\n","# Function to tokenize text and obtain BERT embeddings\n","def tokenize_and_predict(text):\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    predictions = outputs.logits\n","    return predictions\n","\n","# Function to compute percentage\n","def compute_percentage(predictions):\n","    softmax_output = torch.softmax(predictions, dim=1)\n","    positive_percentage = softmax_output[:, 1].item() * 100\n","    negative_percentage = 100 - positive_percentage\n","    return positive_percentage, negative_percentage"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13605,"status":"ok","timestamp":1717904578475,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"9wwBiXG8d_fY","outputId":"a2053773-5b23-49f1-99f1-fa32bae3946f"},"outputs":[{"name":"stdout","output_type":"stream","text":["🤯jobdesk\n","Sentiment: Negative\n","Positive sentiment percentage: 46.032196283340454\n","Negative sentiment percentage: 53.967803716659546\n"]}],"source":["# User input\n","user_text = input(\"\")\n","\n","# Tokenize user input and get predictions\n","user_predictions = tokenize_and_predict(user_text)\n","positive_percentage, negative_percentage = compute_percentage(user_predictions)\n","\n","# Determine sentiment\n","sentiment = \"Positive\" if user_predictions.argmax() == 1 else \"Negative\"\n","\n","print(\"Sentiment:\", sentiment)\n","print(\"Positive sentiment percentage:\", positive_percentage)\n","print(\"Negative sentiment percentage:\", negative_percentage)"]},{"cell_type":"markdown","metadata":{"id":"7sJb4ggwkI9I"},"source":["# Sentimen Analysist Use pretrained Model"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":367,"status":"ok","timestamp":1717895852485,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"bh_rxlqPkSQc"},"outputs":[],"source":["import pandas as pd\n","import torch\n","from transformers import BertTokenizer, BertModel\n","from tqdm import tqdm\n","\n"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":6526,"status":"ok","timestamp":1717895977101,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"ygki6prTkdLg"},"outputs":[],"source":["# Load dataset\n","data = pd.read_excel('/content/drive/MyDrive/AI FOR INDONESIA/Final Project/lowercase_text_only_datasets.xlsx')\n","\n"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":714,"status":"ok","timestamp":1717895978764,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"SpXHTbgvlEZY","outputId":"95037704-ad60-4dd5-d903-bbd0ce9ad93f"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"data\",\n  \"rows\": 54026,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33045,\n        \"samples\": [\n          \"there is lot of fun at workplace and the  project in which i engaged have more scope to innovation that is best part.\",\n          \"maintain office timings in some projects, transport\",\n          \"work from home option till now\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"data"},"text/html":["\n","  <div id=\"df-8dcf4f9b-1573-4a60-94c7-6bdf2d7467f6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>deserved candidates are promoted promptly.\\nun...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>you got lot of learning platform and monthly l...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>based on which business unit you are you will ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>some client projects are good as they use the ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>i have worked in ibm (4 years) ,tcs (1 year) ,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dcf4f9b-1573-4a60-94c7-6bdf2d7467f6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8dcf4f9b-1573-4a60-94c7-6bdf2d7467f6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8dcf4f9b-1573-4a60-94c7-6bdf2d7467f6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b51fe478-a078-4c26-bfa8-3d48eef4fc96\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b51fe478-a078-4c26-bfa8-3d48eef4fc96')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b51fe478-a078-4c26-bfa8-3d48eef4fc96 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                                                text\n","0  deserved candidates are promoted promptly.\\nun...\n","1  you got lot of learning platform and monthly l...\n","2  based on which business unit you are you will ...\n","3  some client projects are good as they use the ...\n","4  i have worked in ibm (4 years) ,tcs (1 year) ,..."]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":4428,"status":"ok","timestamp":1717895988908,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"BHQ0iUlNkezc"},"outputs":[],"source":["# Initialize BERT tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained(\"bert-base-uncased\")\n","\n"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717895988908,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"UJgRNlImkgCH"},"outputs":[],"source":["# Function to tokenize text and obtain BERT embeddings\n","def get_bert_embeddings(text):\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    return outputs.last_hidden_state.mean(dim=1)  # Average pooling over token embeddings\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jyj2pKCXkhq0","outputId":"e6a9313a-d313-49fa-a190-6d844052bae4"},"outputs":[{"name":"stderr","output_type":"stream","text":[" 92%|█████████▏| 49949/54026 [1:34:57<06:43, 10.10it/s]"]}],"source":["# Apply BERT analysis to each text in the dataset\n","output_embeddings = []\n","for text in tqdm(data['text'].astype(str)):\n","    embeddings = get_bert_embeddings(text)\n","    output_embeddings.append(embeddings)\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":1434,"status":"error","timestamp":1717902871289,"user":{"displayName":"Muhammad Habibullah","userId":"00397638864506086087"},"user_tz":-420},"id":"EPwV3QE1kl2F","outputId":"60f9cc35-9445-44a7-9e4b-c8a345428f5e"},"outputs":[{"ename":"NameError","evalue":"name 'output_embeddings' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a571e988a312>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add the BERT analysis results to the dataset as a new column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_Bert'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save the updated dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_dataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'output_embeddings' is not defined"]}],"source":["# Add the BERT analysis results to the dataset as a new column\n","data['output_Bert'] = output_embeddings\n","\n","# Save the updated dataset\n","data.to_csv('output_dataset.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Sentiment Analysist Use Pretrained Model BERT Uncased + Fine tuned from cleaned datasets  \n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["df = pd.read_excel('preprocessing_capegini.xlsx')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>deserved candidate promoted promptly unbiased ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>got lot learning platform monthly learning pla...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>based business unit get experience company pol...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>client project good use latest tech work</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>worked ibm year tc year rd company year comple...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>54022</th>\n","      <td>amazon adopted giving responsibility workplace...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>54023</th>\n","      <td>terrible experience working amazon pay leaders...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>54024</th>\n","      <td>logistics supply management application operat...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>54025</th>\n","      <td>toxic culture depend team hierarchical questio...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>54026</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>54027 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text  sentiment\n","0      deserved candidate promoted promptly unbiased ...        1.0\n","1      got lot learning platform monthly learning pla...        1.0\n","2      based business unit get experience company pol...        1.0\n","3               client project good use latest tech work        1.0\n","4      worked ibm year tc year rd company year comple...        1.0\n","...                                                  ...        ...\n","54022  amazon adopted giving responsibility workplace...        0.0\n","54023  terrible experience working amazon pay leaders...        0.0\n","54024  logistics supply management application operat...        0.0\n","54025  toxic culture depend team hierarchical questio...        0.0\n","54026                                                NaN        NaN\n","\n","[54027 rows x 2 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Remove rows with missing or invalid text data\n","df.dropna(subset=['text', 'sentiment'], inplace=True)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>deserved candidate promoted promptly unbiased ...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>got lot learning platform monthly learning pla...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>based business unit get experience company pol...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>client project good use latest tech work</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>worked ibm year tc year rd company year comple...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>54021</th>\n","      <td>le visibility next level promotion point time ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>54022</th>\n","      <td>amazon adopted giving responsibility workplace...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>54023</th>\n","      <td>terrible experience working amazon pay leaders...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>54024</th>\n","      <td>logistics supply management application operat...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>54025</th>\n","      <td>toxic culture depend team hierarchical questio...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>46416 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text  sentiment\n","0      deserved candidate promoted promptly unbiased ...        1.0\n","1      got lot learning platform monthly learning pla...        1.0\n","2      based business unit get experience company pol...        1.0\n","3               client project good use latest tech work        1.0\n","4      worked ibm year tc year rd company year comple...        1.0\n","...                                                  ...        ...\n","54021  le visibility next level promotion point time ...        0.0\n","54022  amazon adopted giving responsibility workplace...        0.0\n","54023  terrible experience working amazon pay leaders...        0.0\n","54024  logistics supply management application operat...        0.0\n","54025  toxic culture depend team hierarchical questio...        0.0\n","\n","[46416 rows x 2 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["## preparation for sentiment analysis, consists:\n","- encode labels\n","- split data\n","- tokenize the text column on train and val"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Encode sentiment labels\n","label_encoder = LabelEncoder()\n","df['sentiment'] = label_encoder.fit_transform(df['sentiment'])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Split data into train and test sets\n","train_texts, val_texts, train_labels, val_labels = train_test_split(df['text'].tolist(), df['sentiment'].tolist(), test_size=0.2)\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["# GPU check available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Load tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)  # 2 classes: negative and positive\n","model.to(device) # using gpu cuda\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Tokenize data\n","train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=128)\n","val_encodings = tokenizer(val_texts, padding=True, truncation=True, max_length=128)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Create torch dataset\n","class SentimentDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = SentimentDataset(train_encodings, train_labels)\n","val_dataset = SentimentDataset(val_encodings, val_labels)"]},{"cell_type":"markdown","metadata":{},"source":["## fine tuned, results, and save.\n","\n","The fine tuned consists:\n","- epoch: 3\n","-  bath size: 32"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=50,\n","    learning_rate=3e-5\n",")"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["class CustomTrainer(Trainer):\n","    def _prepare_inputs(self, inputs):\n","        # Move inputs to the right device\n","        if torch.cuda.is_available():\n","            inputs = {k: v.to('cuda') for k, v in inputs.items()}\n","        return inputs"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["# Trainer\n","trainer = CustomTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n",")"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  2%|▏         | 79/3483 [18:31<13:17:53, 14.06s/it]\n","                                                   \n","  2%|▏         | 76/3483 [03:09<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6039, 'grad_norm': 7.995917797088623, 'learning_rate': 3e-06, 'epoch': 0.04}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [04:08<1:20:28,  1.42s/it] "]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.585, 'grad_norm': 6.20795202255249, 'learning_rate': 6e-06, 'epoch': 0.09}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [05:07<1:20:28,  1.42s/it] "]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6572, 'grad_norm': 5.559715747833252, 'learning_rate': 9e-06, 'epoch': 0.13}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [06:06<1:20:28,  1.42s/it] "]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6493, 'grad_norm': 3.923051357269287, 'learning_rate': 1.2e-05, 'epoch': 0.17}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [07:05<1:20:28,  1.42s/it] "]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6268, 'grad_norm': 4.417115688323975, 'learning_rate': 1.5e-05, 'epoch': 0.22}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [08:03<1:20:28,  1.42s/it] "]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6404, 'grad_norm': 4.569465637207031, 'learning_rate': 1.8e-05, 'epoch': 0.26}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [09:00<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6208, 'grad_norm': 3.736809253692627, 'learning_rate': 2.1e-05, 'epoch': 0.3}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [09:57<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6309, 'grad_norm': 2.6925530433654785, 'learning_rate': 2.4e-05, 'epoch': 0.34}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [10:54<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6228, 'grad_norm': 3.730441093444824, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.39}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [11:53<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5955, 'grad_norm': 2.6296682357788086, 'learning_rate': 3e-05, 'epoch': 0.43}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [12:53<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6239, 'grad_norm': 3.2641515731811523, 'learning_rate': 2.949715051961113e-05, 'epoch': 0.47}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [13:51<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6038, 'grad_norm': 2.2596938610076904, 'learning_rate': 2.899430103922226e-05, 'epoch': 0.52}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [14:50<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6078, 'grad_norm': 1.7881311178207397, 'learning_rate': 2.8491451558833388e-05, 'epoch': 0.56}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [15:43<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6246, 'grad_norm': 2.4745266437530518, 'learning_rate': 2.7988602078444518e-05, 'epoch': 0.6}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [16:34<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6082, 'grad_norm': 2.407715082168579, 'learning_rate': 2.748575259805565e-05, 'epoch': 0.65}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [17:26<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6104, 'grad_norm': 3.2056241035461426, 'learning_rate': 2.698290311766678e-05, 'epoch': 0.69}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [18:20<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5991, 'grad_norm': 1.8405077457427979, 'learning_rate': 2.648005363727791e-05, 'epoch': 0.73}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [19:14<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6018, 'grad_norm': 2.2860007286071777, 'learning_rate': 2.597720415688904e-05, 'epoch': 0.78}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [20:08<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.618, 'grad_norm': 1.8008999824523926, 'learning_rate': 2.547435467650017e-05, 'epoch': 0.82}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [21:02<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6188, 'grad_norm': 1.8563376665115356, 'learning_rate': 2.49715051961113e-05, 'epoch': 0.86}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [22:00<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5952, 'grad_norm': 1.6813839673995972, 'learning_rate': 2.4468655715722426e-05, 'epoch': 0.9}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [22:55<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5986, 'grad_norm': 1.7797671556472778, 'learning_rate': 2.3965806235333556e-05, 'epoch': 0.95}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [23:49<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6087, 'grad_norm': 2.3820126056671143, 'learning_rate': 2.346295675494469e-05, 'epoch': 0.99}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [24:44<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5741, 'grad_norm': 2.40838623046875, 'learning_rate': 2.296010727455582e-05, 'epoch': 1.03}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [25:40<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5898, 'grad_norm': 2.49617862701416, 'learning_rate': 2.2457257794166946e-05, 'epoch': 1.08}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [26:35<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.594, 'grad_norm': 3.326719045639038, 'learning_rate': 2.1954408313778076e-05, 'epoch': 1.12}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [27:31<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5801, 'grad_norm': 2.1797850131988525, 'learning_rate': 2.1451558833389206e-05, 'epoch': 1.16}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [28:26<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5839, 'grad_norm': 2.2415149211883545, 'learning_rate': 2.0948709353000336e-05, 'epoch': 1.21}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [29:22<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5861, 'grad_norm': 1.9618936777114868, 'learning_rate': 2.0445859872611463e-05, 'epoch': 1.25}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [30:18<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.583, 'grad_norm': 1.9430819749832153, 'learning_rate': 1.9943010392222593e-05, 'epoch': 1.29}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [31:17<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5968, 'grad_norm': 5.654139995574951, 'learning_rate': 1.9440160911833727e-05, 'epoch': 1.34}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [32:13<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6028, 'grad_norm': 1.373599648475647, 'learning_rate': 1.8937311431444857e-05, 'epoch': 1.38}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [33:09<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6044, 'grad_norm': 2.2413198947906494, 'learning_rate': 1.8434461951055984e-05, 'epoch': 1.42}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [34:05<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6088, 'grad_norm': 3.0875980854034424, 'learning_rate': 1.7931612470667114e-05, 'epoch': 1.46}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [35:01<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5715, 'grad_norm': 2.6904196739196777, 'learning_rate': 1.7428762990278244e-05, 'epoch': 1.51}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [35:57<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5668, 'grad_norm': 1.7949897050857544, 'learning_rate': 1.6925913509889374e-05, 'epoch': 1.55}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [36:53<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5719, 'grad_norm': 3.053746461868286, 'learning_rate': 1.64230640295005e-05, 'epoch': 1.59}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [37:49<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5912, 'grad_norm': 2.0147759914398193, 'learning_rate': 1.592021454911163e-05, 'epoch': 1.64}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [38:45<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5607, 'grad_norm': 1.8114467859268188, 'learning_rate': 1.5417365068722765e-05, 'epoch': 1.68}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [39:41<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5964, 'grad_norm': 2.3230390548706055, 'learning_rate': 1.4914515588333891e-05, 'epoch': 1.72}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [40:40<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5676, 'grad_norm': 2.3647232055664062, 'learning_rate': 1.4411666107945023e-05, 'epoch': 1.77}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [41:36<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.592, 'grad_norm': 1.8679039478302002, 'learning_rate': 1.3908816627556152e-05, 'epoch': 1.81}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [42:33<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5901, 'grad_norm': 1.468088150024414, 'learning_rate': 1.3405967147167282e-05, 'epoch': 1.85}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [43:29<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5846, 'grad_norm': 3.028562068939209, 'learning_rate': 1.290311766677841e-05, 'epoch': 1.89}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [44:25<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.569, 'grad_norm': 3.046839475631714, 'learning_rate': 1.240026818638954e-05, 'epoch': 1.94}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [45:21<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5899, 'grad_norm': 1.7646021842956543, 'learning_rate': 1.189741870600067e-05, 'epoch': 1.98}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [46:17<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5912, 'grad_norm': 3.191164493560791, 'learning_rate': 1.13945692256118e-05, 'epoch': 2.02}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [47:13<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5531, 'grad_norm': 3.127356767654419, 'learning_rate': 1.0891719745222929e-05, 'epoch': 2.07}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [48:09<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5432, 'grad_norm': 1.7282863855361938, 'learning_rate': 1.038887026483406e-05, 'epoch': 2.11}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [49:04<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5408, 'grad_norm': 2.9119255542755127, 'learning_rate': 9.88602078444519e-06, 'epoch': 2.15}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [50:03<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5606, 'grad_norm': 3.539696216583252, 'learning_rate': 9.38317130405632e-06, 'epoch': 2.2}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [50:59<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5435, 'grad_norm': 2.8829903602600098, 'learning_rate': 8.880321823667448e-06, 'epoch': 2.24}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [51:55<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5359, 'grad_norm': 2.409550666809082, 'learning_rate': 8.377472343278578e-06, 'epoch': 2.28}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [52:50<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5526, 'grad_norm': 1.9949469566345215, 'learning_rate': 7.87462286288971e-06, 'epoch': 2.33}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [53:46<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5836, 'grad_norm': 2.5176985263824463, 'learning_rate': 7.371773382500838e-06, 'epoch': 2.37}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [54:42<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5359, 'grad_norm': 2.811687469482422, 'learning_rate': 6.868923902111968e-06, 'epoch': 2.41}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [55:37<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5562, 'grad_norm': 1.7371596097946167, 'learning_rate': 6.366074421723098e-06, 'epoch': 2.45}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [56:33<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5606, 'grad_norm': 2.4067986011505127, 'learning_rate': 5.863224941334227e-06, 'epoch': 2.5}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [57:29<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5518, 'grad_norm': 2.2243287563323975, 'learning_rate': 5.360375460945357e-06, 'epoch': 2.54}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [58:25<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.564, 'grad_norm': 2.4572155475616455, 'learning_rate': 4.8575259805564865e-06, 'epoch': 2.58}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [59:23<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5407, 'grad_norm': 2.7758336067199707, 'learning_rate': 4.354676500167617e-06, 'epoch': 2.63}\n"]},{"name":"stderr","output_type":"stream","text":["                                                   \n","  2%|▏         | 76/3483 [1:00:18<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5572, 'grad_norm': 3.165695905685425, 'learning_rate': 3.851827019778746e-06, 'epoch': 2.67}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","  2%|▏         | 76/3483 [1:01:14<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5291, 'grad_norm': 2.412881851196289, 'learning_rate': 3.348977539389876e-06, 'epoch': 2.71}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","  2%|▏         | 76/3483 [1:02:09<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.561, 'grad_norm': 1.4612728357315063, 'learning_rate': 2.846128059001006e-06, 'epoch': 2.76}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","  2%|▏         | 76/3483 [1:03:05<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5211, 'grad_norm': 2.5966286659240723, 'learning_rate': 2.3432785786121355e-06, 'epoch': 2.8}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","  2%|▏         | 76/3483 [1:04:00<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5485, 'grad_norm': 1.788744330406189, 'learning_rate': 1.840429098223265e-06, 'epoch': 2.84}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","  2%|▏         | 76/3483 [1:04:56<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5436, 'grad_norm': 2.129650354385376, 'learning_rate': 1.3375796178343948e-06, 'epoch': 2.89}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","  2%|▏         | 76/3483 [1:05:51<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5619, 'grad_norm': 2.93367600440979, 'learning_rate': 8.347301374455247e-07, 'epoch': 2.93}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","  2%|▏         | 76/3483 [1:06:47<1:20:28,  1.42s/it]"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5495, 'grad_norm': 2.4409220218658447, 'learning_rate': 3.3188065705665436e-07, 'epoch': 2.97}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","100%|██████████| 3483/3483 [1:05:15<00:00,  1.12s/it]"]},{"name":"stdout","output_type":"stream","text":["{'train_runtime': 3915.6233, 'train_samples_per_second': 28.449, 'train_steps_per_second': 0.89, 'train_loss': 0.5836303731746931, 'epoch': 3.0}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["TrainOutput(global_step=3483, training_loss=0.5836303731746931, metrics={'train_runtime': 3915.6233, 'train_samples_per_second': 28.449, 'train_steps_per_second': 0.89, 'total_flos': 7327379780720640.0, 'train_loss': 0.5836303731746931, 'epoch': 3.0})"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Train model\n","trainer.train()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 291/291 [01:25<00:00,  3.39it/s]"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.619106650352478, 'eval_runtime': 86.0218, 'eval_samples_per_second': 107.926, 'eval_steps_per_second': 3.383, 'epoch': 3.0}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Evaluate model\n","results = trainer.evaluate()\n","print(results)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["('D:\\\\Project\\\\Final Project Indonesia AI/02_11062024_bert_sentiment_model\\\\tokenizer_config.json',\n"," 'D:\\\\Project\\\\Final Project Indonesia AI/02_11062024_bert_sentiment_model\\\\special_tokens_map.json',\n"," 'D:\\\\Project\\\\Final Project Indonesia AI/02_11062024_bert_sentiment_model\\\\vocab.txt',\n"," 'D:\\\\Project\\\\Final Project Indonesia AI/02_11062024_bert_sentiment_model\\\\added_tokens.json')"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# Save model pretrained model for hugging face\n","output_dir=\"D:\\Project\\Final Project Indonesia AI/02_11062024_bert_sentiment_model\"\n","model.save_pretrained(output_dir, from_pt=True)\n","tokenizer.save_pretrained(output_dir)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"list indices must be integers or slices, not str","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[41], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming `trainer` is your Trainer object with training history\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_history\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m eval_loss \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlog_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Plot loss over epochs\u001b[39;00m\n","\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"]}],"source":["# import matplotlib.pyplot as plt\n","\n","# # Assuming `trainer` is your Trainer object with training history\n","# train_loss = trainer.state.log_history['loss']\n","# eval_loss = trainer.state.log_history['eval_loss']\n","\n","# # Plot loss over epochs\n","# plt.plot(range(len(train_loss)), train_loss, label='Train Loss')\n","# plt.plot(range(len(eval_loss)), eval_loss, label='Eval Loss')\n","# plt.xlabel('Epoch')\n","# plt.ylabel('Loss')\n","# plt.title('Training and Evaluation Loss')\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## testing the fine tuned models with cleaned dataset"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Load tokenizer and fine-tuned model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained(\"02_11062024_bert_sentiment_model\") # the fine tuned model save\n","\n","# Function to tokenize text and obtain BERT embeddings\n","def tokenize_and_predict(text):\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    predictions = outputs.logits\n","    return predictions\n","\n","# Function to compute percentage\n","def compute_percentage(predictions):\n","    softmax_output = torch.softmax(predictions, dim=1)\n","    positive_percentage = softmax_output[:, 1].item() * 100\n","    negative_percentage = 100 - positive_percentage\n","    return positive_percentage, negative_percentage"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentiment: Negative\n","Positive sentiment percentage: 40.34416675567627\n","Negative sentiment percentage: 59.65583324432373\n"]}],"source":["# User input\n","user_text = (\"🤯jobdesk\")\n","\n","# Tokenize user input and get predictions\n","user_predictions = tokenize_and_predict(user_text)\n","positive_percentage, negative_percentage = compute_percentage(user_predictions)\n","\n","# Determine sentiment\n","sentiment = \"Positive\" if user_predictions.argmax() == 1 else \"Negative\"\n","\n","print(\"Sentiment:\", sentiment)\n","print(\"Positive sentiment percentage:\", positive_percentage)\n","print(\"Negative sentiment percentage:\", negative_percentage)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPDaEt4cZUNyJ0Q+YD66J4/","gpuType":"T4","mount_file_id":"1NGNyVNx9rbiyBLEAWwb05yNmQytqWi3-","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00fd29a8fbd54e1fa1575a8057ce20cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a266cc6ea9041d09b238a5481a0dee3","placeholder":"​","style":"IPY_MODEL_d6f3a38738c8483cbc49409ca80e3f00","value":" 232k/232k [00:00&lt;00:00, 2.51MB/s]"}},"04ab51d54ef64aa5afa1a01ad51f9e96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0d90a99f1ac44aa99d598e69b3ac779","placeholder":"​","style":"IPY_MODEL_b1eca0741afa489ea780cc29cc4fa8b6","value":" 466k/466k [00:00&lt;00:00, 2.30MB/s]"}},"09c35363060046c780ae96043fcb26ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ab896d37b3e4fbeac970a84426d1dbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35a0521f3cba4915b323e0761f6ea880","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b119b7391aa44b8896b2023a286b4e4","value":466062}},"18582fa25f5648d4a8010f7d07cd10d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5f4bcc0bf78414f9c6e8617349a145e","IPY_MODEL_7e58f7f4e3d643eab559496508dc6053","IPY_MODEL_4cbdbc98da944ff4b0c1301dc8b393fa"],"layout":"IPY_MODEL_c21c02c3fc4c453787cfa8db05958570"}},"214e9bf70436439a90fb7001c8a4545b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21f58654e03e48d7a1dc2fdaff99239d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3089b6978c4f422eb6f50da8a783a6a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb0f0fc66d174950baecd017cc026433","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2c0edfd5782428cb5b12a1c31842bcb","value":48}},"35a0521f3cba4915b323e0761f6ea880":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a266cc6ea9041d09b238a5481a0dee3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41ac6c0a38614bc98c3fc989d22f13ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cbdbc98da944ff4b0c1301dc8b393fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cbe3c51c2b24c9791a70ed2870efe6b","placeholder":"​","style":"IPY_MODEL_c73cadac8b784228b713329aba3f0c5d","value":" 570/570 [00:00&lt;00:00, 30.1kB/s]"}},"4d54f7ebfdc54b22bad28b5051661d98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59b23f47f7f14214804e78f450655eb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f1fbfd0fccf4f20bf8a53d56a07aaf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c3f9fac3bfe4f29ae90bcb675764934","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_89de5a5d3705416bb0d9ff3793c8d66d","value":231508}},"63042bbc8e114aefa2569fdb6c412a6d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64e2a92dc167485daefc082eaab58ded":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"672cd94584ab4150b44715ef793212da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4dd87a5c6794b65ad6b521b1785f0c7","IPY_MODEL_3089b6978c4f422eb6f50da8a783a6a0","IPY_MODEL_f5404cd32ac34cf1aa0c76018c82d124"],"layout":"IPY_MODEL_943a2deec10e45fb8f6798b0fdfb6db9"}},"6b119b7391aa44b8896b2023a286b4e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6cbe3c51c2b24c9791a70ed2870efe6b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"762646ebb59249289de8855f8a0f0e5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e58f7f4e3d643eab559496508dc6053":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d54f7ebfdc54b22bad28b5051661d98","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21f58654e03e48d7a1dc2fdaff99239d","value":570}},"85c036d23fbb484d9c332347138ccd33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89de5a5d3705416bb0d9ff3793c8d66d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"943a2deec10e45fb8f6798b0fdfb6db9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c3f9fac3bfe4f29ae90bcb675764934":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1eca0741afa489ea780cc29cc4fa8b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b584a642800a4227a67f5f5ef5598d83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db82d79f2c124a90b2918c4dfc8b88fe","IPY_MODEL_0ab896d37b3e4fbeac970a84426d1dbc","IPY_MODEL_04ab51d54ef64aa5afa1a01ad51f9e96"],"layout":"IPY_MODEL_214e9bf70436439a90fb7001c8a4545b"}},"b5f4bcc0bf78414f9c6e8617349a145e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_762646ebb59249289de8855f8a0f0e5b","placeholder":"​","style":"IPY_MODEL_09c35363060046c780ae96043fcb26ad","value":"config.json: 100%"}},"bb0f0fc66d174950baecd017cc026433":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc5b3fea4bcd4a2cb8748d2e616b6946":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c21c02c3fc4c453787cfa8db05958570":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c73cadac8b784228b713329aba3f0c5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8e880ce1c3c42dabcfff424d84c74bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d29a04973ea246dc94095f0dd4394009","placeholder":"​","style":"IPY_MODEL_64e2a92dc167485daefc082eaab58ded","value":"vocab.txt: 100%"}},"d0d90a99f1ac44aa99d598e69b3ac779":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d29a04973ea246dc94095f0dd4394009":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2c0edfd5782428cb5b12a1c31842bcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6f3a38738c8483cbc49409ca80e3f00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db82d79f2c124a90b2918c4dfc8b88fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc5b3fea4bcd4a2cb8748d2e616b6946","placeholder":"​","style":"IPY_MODEL_59b23f47f7f14214804e78f450655eb8","value":"tokenizer.json: 100%"}},"de60dfcbba0e4ac2a1014db8937976fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e843a8800b6e42de9e5419df0d9d2eab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8e880ce1c3c42dabcfff424d84c74bb","IPY_MODEL_5f1fbfd0fccf4f20bf8a53d56a07aaf4","IPY_MODEL_00fd29a8fbd54e1fa1575a8057ce20cf"],"layout":"IPY_MODEL_63042bbc8e114aefa2569fdb6c412a6d"}},"eb337219fe6d4683a2372f1b589021ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4dd87a5c6794b65ad6b521b1785f0c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41ac6c0a38614bc98c3fc989d22f13ac","placeholder":"​","style":"IPY_MODEL_85c036d23fbb484d9c332347138ccd33","value":"tokenizer_config.json: 100%"}},"f5404cd32ac34cf1aa0c76018c82d124":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb337219fe6d4683a2372f1b589021ec","placeholder":"​","style":"IPY_MODEL_de60dfcbba0e4ac2a1014db8937976fb","value":" 48.0/48.0 [00:00&lt;00:00, 1.17kB/s]"}}}}},"nbformat":4,"nbformat_minor":0}
